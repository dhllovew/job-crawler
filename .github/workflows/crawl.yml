name: Job Crawler

on:
  schedule:
    - cron: '30 15 * * *'  # 每天UTC时间9:00运行（北京时间17:00）
  workflow_dispatch:     # 允许手动触发

jobs:
  crawl:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # 需要写入权限来更新数据文件
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver libgbm-dev
      
      - name: Configure ChromeDriver
        run: |
          # 确保ChromeDriver路径正确
          echo "CHROME_PATH=/usr/bin/chromium-browser" >> $GITHUB_ENV
          echo "CHROMEDRIVER_PATH=/usr/bin/chromedriver" >> $GITHUB_ENV
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium pandas fake-useragent PyGithub
      
      - name: Run crawler
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PWD: ${{ secrets.EMAIL_PWD }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_NAME: ${{ github.repository }}  # 自动使用当前仓库
        run: python crawler_github.py
