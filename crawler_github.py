#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¡å›­æ‹›è˜ä¸å®ä¹ ä¿¡æ¯çˆ¬è™«å·¥å…·

åŠŸèƒ½ï¼š
- çˆ¬å–æŒ‡å®šç½‘ç«™çš„æ ¡æ‹›å’Œå®ä¹ å²—ä½ä¿¡æ¯
- ç­›é€‰2026å±Šç›¸å…³èŒä½
- ä¿å­˜æ•°æ®åˆ°JSONå’ŒExcelï¼ˆæ–°å¢èŒä½é«˜äº®ï¼‰
- è‡ªåŠ¨å‘é€é‚®ä»¶é€šçŸ¥æ–°èŒä½ä¿¡æ¯

ä½¿ç”¨å‰è¯·é…ç½®ç¯å¢ƒå˜é‡ï¼š
- EMAIL_USER: å‘é€é‚®ç®±è´¦å·
- EMAIL_PWD: å‘é€é‚®ç®±æˆæƒç 
- RECEIVER_EMAILS: æ¥æ”¶é‚®ç®±åˆ—è¡¨ï¼ˆåˆ†å·åˆ†éš”ï¼‰
"""

import os
import time
import json
import logging
import smtplib
import random
import pandas as pd
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from fake_useragent import UserAgent
import openpyxl
import html

# ============================
# é…ç½®ä¸åˆå§‹åŒ–
# ============================

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
START_PAGE = 1  # èµ·å§‹é¡µç 
END_PAGE = 6    # ç›®æ ‡æ€»é¡µç 
MAX_PAGES_PER_SESSION = 2  # æ¯æ¬¡ä¼šè¯æœ€å¤§çˆ¬å–é¡µæ•°ï¼ˆååçˆ¬ç­–ç•¥ï¼‰
WAIT_TIME_MIN = 1  # é¡µé¢ç­‰å¾…æœ€å°æ—¶é—´ï¼ˆç§’ï¼‰
WAIT_TIME_MAX = 3  # é¡µé¢ç­‰å¾…æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰

# ç›®æ ‡ç½‘ç«™URL
SITE_URL = "https://www.givemeoc.com"  # æ ¡æ‹›å²—ä½é¡µé¢
SITE_URL_INTERNSHIP = "https://www.givemeoc.com/internship"  # å®ä¹ å²—ä½é¡µé¢

# æ•°æ®å­˜å‚¨è·¯å¾„
DATA_FILE_CAMPUS = "campus_jobs.json"       # æ ¡æ‹›æ•°æ®JSONæ–‡ä»¶
DATA_FILE_INTERNSHIP = "intern_jobs.json"   # å®ä¹ æ•°æ®JSONæ–‡ä»¶
EXCEL_FILE_CAMPUS = "campus_jobs.xlsx"      # æ ¡æ‹›æ•°æ®Excelæ–‡ä»¶
EXCEL_FILE_INTERNSHIP = "intern_jobs.xlsx"  # å®ä¹ æ•°æ®Excelæ–‡ä»¶

# é‚®ç®±é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
EMAIL_USER = os.environ.get('EMAIL_USER')  # å‘é€é‚®ç®±è´¦å·
EMAIL_PWD = os.environ.get('EMAIL_PWD')    # å‘é€é‚®ç®±æˆæƒç 
RECEIVER_EMAILS = os.environ.get('RECEIVER_EMAILS', '').split(';')  # æ¥æ”¶é‚®ç®±åˆ—è¡¨


# ============================
# å·¥å…·å‡½æ•°
# ============================

def is_target_recruitment(target):
    """åˆ¤æ–­æ˜¯å¦ä¸º2026å±Šç›¸å…³æ‹›è˜
    
    å‚æ•°:
        target: æ‹›è˜å¯¹è±¡æè¿°æ–‡æœ¬
        
    è¿”å›:
        bool: è‹¥åŒ…å«2026å±Šç›¸å…³å…³é”®è¯åˆ™è¿”å›Trueï¼Œå¦åˆ™False
    """
    if not target:
        return False
    target_lower = target.lower()
    return '2026' in target_lower or '26å±Š' in target_lower


def safe_get_text(element, selector):
    """å®‰å…¨è·å–å…ƒç´ æ–‡æœ¬ï¼ˆé¿å…å› å…ƒç´ ä¸å­˜åœ¨å¯¼è‡´æŠ¥é”™ï¼‰
    
    å‚æ•°:
        element: çˆ¶å…ƒç´ å¯¹è±¡
        selector: CSSé€‰æ‹©å™¨
        
    è¿”å›:
        str: å…ƒç´ æ–‡æœ¬ï¼ˆè‹¥è·å–å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    try:
        return element.find_element("css selector", selector).text
    except:
        return ""


def safe_get_attr(element, selector, attribute):
    """å®‰å…¨è·å–å…ƒç´ å±æ€§ï¼ˆé¿å…å› å…ƒç´ ä¸å­˜åœ¨å¯¼è‡´æŠ¥é”™ï¼‰
    
    å‚æ•°:
        element: çˆ¶å…ƒç´ å¯¹è±¡
        selector: CSSé€‰æ‹©å™¨
        attribute: è¦è·å–çš„å±æ€§å
        
    è¿”å›:
        str: å…ƒç´ å±æ€§å€¼ï¼ˆè‹¥è·å–å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    try:
        return element.find_element("css selector", selector).get_attribute(attribute)
    except:
        return ""


# ============================
# æ•°æ®å¤„ç†å‡½æ•°
# ============================

def load_and_clean_historical_data(data_file):
    """åŠ è½½å¹¶æ¸…ç†å†å²æ•°æ®ï¼ˆä»…ä¿ç•™2026å±Šç›¸å…³èŒä½ï¼‰
    
    å‚æ•°:
        data_file: å†å²æ•°æ®JSONæ–‡ä»¶è·¯å¾„
        
    è¿”å›:
        dict: æ¸…ç†åçš„å†å²æ•°æ®å­—å…¸ï¼Œç»“æ„ä¸º:
            {
                "last_update": æœ€åæ›´æ–°æ—¶é—´ISOå­—ç¬¦ä¸²,
                "jobs": {èŒä½ID: èŒä½è¯¦æƒ…å­—å…¸}
            }
    """
    try:
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                historical_data = json.load(f)
            
            # ç­›é€‰ä¿ç•™2026å±Šç›¸å…³èŒä½
            original_count = len(historical_data.get("jobs", {}))
            filtered_jobs = {}
            for job_id, job in historical_data.get("jobs", {}).items():
                if is_target_recruitment(job.get("target", "")):
                    filtered_jobs[job_id] = job
            
            # æ›´æ–°å†å²æ•°æ®
            historical_data["jobs"] = filtered_jobs
            historical_data["last_clean_time"] = datetime.now().isoformat()
            
            # è®°å½•æ¸…ç†ç»“æœ
            removed_count = original_count - len(filtered_jobs)
            if removed_count > 0:
                logger.info(f"æ¸…ç† {data_file}: ç§»é™¤ {removed_count} æ¡é2026å±ŠèŒä½ï¼Œä¿ç•™ {len(filtered_jobs)} æ¡")
                with open(data_file, 'w', encoding='utf-8') as f:
                    json.dump(historical_data, f, ensure_ascii=False, indent=2)
            else:
                logger.info(f"{data_file} æ‰€æœ‰ {original_count} æ¡å‡ä¸º2026å±Šç›¸å…³èŒä½")
            
            return historical_data
        else:
            logger.info(f"é¦–æ¬¡è¿è¡Œï¼Œåˆå§‹åŒ–æ•°æ®æ–‡ä»¶: {data_file}")
            return {"last_update": None, "jobs": {}}
    except Exception as e:
        logger.warning(f"åŠ è½½å†å²æ•°æ®å¤±è´¥ï¼Œåˆ›å»ºæ–°æ•°æ®é›†: {e}")
        return {"last_update": None, "jobs": {}}


def save_historical_data(data, data_file):
    """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°JSONæ–‡ä»¶
    
    å‚æ•°:
        data: è¦ä¿å­˜çš„æ•°æ®å­—å…¸
        data_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        
    è¿”å›:
        bool: ä¿å­˜æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™False
    """
    try:
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"æ•°æ®å·²ä¿å­˜è‡³: {data_file}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        return False


def clean_expired_jobs(historical_data):
    """æ¸…ç†è¿‡æœŸèŒä½ï¼ˆæˆªæ­¢æ—¥æœŸå·²è¿‡ï¼‰å’Œé2026å±ŠèŒä½
    
    å‚æ•°:
        historical_data: åŸå§‹å†å²æ•°æ®å­—å…¸
        
    è¿”å›:
        dict: æ¸…ç†åçš„å†å²æ•°æ®å­—å…¸
    """
    logger.info("å¼€å§‹æ¸…ç†è¿‡æœŸèŒä½...")
    current_time = datetime.now()
    expired_count = 0
    non_target_count = 0
    jobs_to_keep = {}
    
    for job_id, job in historical_data['jobs'].items():
        # è¿‡æ»¤é2026å±ŠèŒä½
        if not is_target_recruitment(job.get("target", "")):
            non_target_count += 1
            continue
            
        # è¿‡æ»¤è¿‡æœŸèŒä½
        if job.get('deadline'):
            try:
                deadline_date = datetime.strptime(job['deadline'], "%Y-%m-%d")
                if deadline_date < current_time:
                    expired_count += 1
                    continue
            except:
                pass  # æ— æ³•è§£æçš„æ—¥æœŸè§†ä¸ºæœªè¿‡æœŸ
                
        jobs_to_keep[job_id] = job
    
    historical_data['jobs'] = jobs_to_keep
    logger.info(f"æ¸…ç†å®Œæˆ: ç§»é™¤ {expired_count} æ¡è¿‡æœŸèŒä½ï¼Œ{non_target_count} æ¡é2026å±ŠèŒä½ï¼Œä¿ç•™ {len(jobs_to_keep)} æ¡æœ‰æ•ˆèŒä½")
    return historical_data


# ============================
# çˆ¬è™«æ ¸å¿ƒå‡½æ•°
# ============================

def setup_browser():
    """é…ç½®æµè§ˆå™¨å®ä¾‹ï¼ˆå¸¦ååçˆ¬ç­–ç•¥ï¼‰
    
    è¿”å›:
        webdriver.Chrome: é…ç½®å¥½çš„æµè§ˆå™¨é©±åŠ¨å®ä¾‹
    """
    chrome_options = Options()
    # åŸºç¡€é…ç½®
    chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼ï¼ˆæ— ç•Œé¢è¿è¡Œï¼‰
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument("--incognito")  # æ— ç—•æ¨¡å¼
    
    # ååçˆ¬é…ç½®
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
    chrome_options.binary_location = "/usr/bin/chromium-browser"  # GitHub Actionså…¼å®¹
    
    # éšæœºUser-Agent
    ua = UserAgent()
    chrome_options.add_argument(f"user-agent={ua.random}")
    
    # åˆå§‹åŒ–é©±åŠ¨
    driver = webdriver.Chrome(options=chrome_options)
    
    # è¿›ä¸€æ­¥éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'
    })
    
    logger.info("æµè§ˆå™¨å®ä¾‹åˆå§‹åŒ–å®Œæˆ")
    return driver


def crawl_campus_data(driver, site_url, start_page, end_page):
    """çˆ¬å–æ ¡æ‹›é¡µé¢æ•°æ®ï¼ˆç­›é€‰2026å±Šç›¸å…³èŒä½ï¼‰
    
    å‚æ•°:
        driver: æµè§ˆå™¨é©±åŠ¨å®ä¾‹
        site_url: æ ¡æ‹›é¡µé¢åŸºç¡€URL
        start_page: èµ·å§‹é¡µç 
        end_page: ç›®æ ‡ç»“æŸé¡µç 
        
    è¿”å›:
        tuple: (çˆ¬å–çš„èŒä½åˆ—è¡¨, å®é™…çˆ¬å–çš„æœ€åé¡µç )
    """
    try:
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # è·³è½¬åˆ°èµ·å§‹é¡µï¼ˆè‹¥ä¸æ˜¯ç¬¬1é¡µï¼‰
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°æ ¡æ‹›ç¬¬ {start_page} é¡µ")
                page_input = driver.find_element("css selector", "input.crt-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))
                go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)  # é¿å…è¢«æ£€æµ‹ä¸ºè‡ªåŠ¨åŒ–ç‚¹å‡»
                time.sleep(random.gauss(3, 1))  # é«˜æ–¯åˆ†å¸ƒç­‰å¾…ï¼ˆæ›´æ¥è¿‘äººç±»è¡Œä¸ºï¼‰
            except Exception as e:
                logger.error(f"æ ¡æ‹›è·³è½¬è‡³ç¬¬ {start_page} é¡µå¤±è´¥: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # çˆ¬å–å½“å‰ä¼šè¯åˆ†é…çš„é¡µæ•°ï¼ˆæœ€å¤š2é¡µï¼‰
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"çˆ¬å–æ ¡æ‹›ç¬¬ {page} é¡µ")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£æèŒä½åˆ—è¡¨
            job_items = driver.find_elements("css selector", "table.crt-table tbody tr")
            for item in job_items:
                try:
                    # æå–èŒä½ä¿¡æ¯
                    job_info = {
                        "job_type": "æ ¡æ‹›",
                        "company": safe_get_text(item, "td.crt-col-company"),
                        "company_type": safe_get_text(item, "td.crt-col-type"),
                        "location": safe_get_text(item, "td.crt-col-recruitment-type + td"),
                        "recruitment_type": safe_get_text(item, "td.crt-col-recruitment-type"),
                        "target": safe_get_text(item, "td.crt-col-target"),
                        "position": safe_get_text(item, "td.crt-col-position"),
                        "update_time": safe_get_text(item, "td.crt-col-update-time"),
                        "deadline": safe_get_text(item, "td.crt-col-deadline"),
                        "links": safe_get_attr(item, "td.crt-col-links a", "href"),
                        "notice": safe_get_attr(item, "td.crt-col-notice a", "href"),
                        "referral": safe_get_text(item, "td.crt-col-referral"),
                        "notes": safe_get_text(item, "td.crt-col-notes"),
                        "crawl_time": datetime.now().isoformat()
                    }

                    # ç­›é€‰2026å±Šç›¸å…³èŒä½
                    if is_target_recruitment(job_info["target"]):
                        crawled_data.append(job_info)
                    else:
                        logger.debug(f"è¿‡æ»¤é2026å±ŠèŒä½: {job_info['company']} - {job_info['position']}")
                except Exception as e:
                    logger.warning(f"å¤„ç†æ ¡æ‹›èŒä½å¤±è´¥: {e}")
                    continue

            # ç¿»åˆ°ä¸‹ä¸€é¡µï¼ˆè‹¥æœªè¾¾å½“å‰ä¼šè¯ç»ˆç‚¹ï¼‰
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    page_input = driver.find_element("css selector", "input.crt-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))
                    go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                except Exception as e:
                    logger.warning(f"æ ¡æ‹›ç¿»é¡µå¤±è´¥: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"æ ¡æ‹›çˆ¬å–å¤±è´¥: {e}")
        return [], start_page


def crawl_internship_data(driver, site_url, start_page, end_page):
    """çˆ¬å–å®ä¹ é¡µé¢æ•°æ®ï¼ˆç­›é€‰2026å±Šç›¸å…³èŒä½ï¼‰
    
    å‚æ•°:
        driver: æµè§ˆå™¨é©±åŠ¨å®ä¾‹
        site_url: å®ä¹ é¡µé¢åŸºç¡€URL
        start_page: èµ·å§‹é¡µç 
        end_page: ç›®æ ‡ç»“æŸé¡µç 
        
    è¿”å›:
        tuple: (çˆ¬å–çš„èŒä½åˆ—è¡¨, å®é™…çˆ¬å–çš„æœ€åé¡µç )
    """
    try:
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # è·³è½¬åˆ°èµ·å§‹é¡µï¼ˆè‹¥ä¸æ˜¯ç¬¬1é¡µï¼‰
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°å®ä¹ ç¬¬ {start_page} é¡µ")
                page_input = driver.find_element("css selector", "input.int-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))
                go_button = driver.find_element("css selector", "button.int-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)
                time.sleep(random.gauss(3, 1))
            except Exception as e:
                logger.error(f"å®ä¹ è·³è½¬è‡³ç¬¬ {start_page} é¡µå¤±è´¥: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # çˆ¬å–å½“å‰ä¼šè¯åˆ†é…çš„é¡µæ•°ï¼ˆæœ€å¤š2é¡µï¼‰
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"çˆ¬å–å®ä¹ ç¬¬ {page} é¡µ")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£æèŒä½åˆ—è¡¨
            job_items = driver.find_elements("css selector", "table.int-table tbody tr")
            for item in job_items:
                try:
                    # æå–èŒä½ä¿¡æ¯
                    job_info = {
                        "job_type": "å®ä¹ ",
                        "company": safe_get_text(item, "td.int-col-company"),
                        "company_type": safe_get_text(item, "td.int-col-type"),
                        "location": safe_get_text(item, "td.int-col-recruitment-type + td"),
                        "recruitment_type": safe_get_text(item, "td.int-col-recruitment-type"),
                        "target": safe_get_text(item, "td.int-col-target"),
                        "position": safe_get_text(item, "td.int-col-position"),
                        "update_time": safe_get_text(item, "td.int-col-update-time"),
                        "deadline": safe_get_text(item, "td.int-col-deadline"),
                        "links": safe_get_attr(item, "td.int-col-links a", "href"),
                        "notice": safe_get_attr(item, "td.int-col-notice a", "href"),
                        "referral": safe_get_text(item, "td.int-col-referral"),
                        "notes": safe_get_text(item, "td.int-col-notes"),
                        "crawl_time": datetime.now().isoformat()
                    }

                    # ç­›é€‰2026å±Šç›¸å…³èŒä½
                    if is_target_recruitment(job_info["target"]):
                        crawled_data.append(job_info)
                    else:
                        logger.debug(f"è¿‡æ»¤é2026å±ŠèŒä½: {job_info['company']} - {job_info['position']}")
                except Exception as e:
                    logger.warning(f"å¤„ç†å®ä¹ èŒä½å¤±è´¥: {e}")
                    continue

            # ç¿»åˆ°ä¸‹ä¸€é¡µï¼ˆè‹¥æœªè¾¾å½“å‰ä¼šè¯ç»ˆç‚¹ï¼‰
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    page_input = driver.find_element("css selector", "input.int-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))
                    go_button = driver.find_element("css selector", "button.int-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                except Exception as e:
                    logger.warning(f"å®ä¹ ç¿»é¡µå¤±è´¥: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"å®ä¹ çˆ¬å–å¤±è´¥: {e}")
        return [], start_page


# ============================
# è¾“å‡ºä¸é€šçŸ¥å‡½æ•°
# ============================

def save_excel_file(job_list, filename, added_jobs=None):
    """å°†èŒä½æ•°æ®ä¿å­˜ä¸ºExcelï¼ˆæ–°å¢èŒä½é«˜äº®ï¼‰
    
    å‚æ•°:
        job_list: èŒä½åˆ—è¡¨
        filename: ç›®æ ‡Excelè·¯å¾„
        added_jobs: æ–°å¢èŒä½åˆ—è¡¨ï¼ˆç”¨äºé«˜äº®æ ‡è®°ï¼‰
        
    è¿”å›:
        bool: ä¿å­˜æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™False
    """
    try:
        # åˆ—åæ˜ å°„ï¼ˆä¸­æ–‡æ˜¾ç¤ºï¼‰
        CN_HEADERS = {
            "company": "å…¬å¸åç§°",
            "company_type": "å…¬å¸ç±»å‹",
            "location": "å·¥ä½œåœ°ç‚¹",
            "recruitment_type": "æ‹›è˜ç±»å‹",
            "target": "æ‹›è˜å¯¹è±¡",
            "position": "èŒä½åç§°",
            "update_time": "æ›´æ–°æ—¶é—´",
            "deadline": "æˆªæ­¢æ—¶é—´",
            "links": "èŒä½é“¾æ¥",
            "notice": "é€šçŸ¥é“¾æ¥",
            "referral": "å†…æ¨ä¿¡æ¯",
            "notes": "å¤‡æ³¨",
            "crawl_time": "çˆ¬å–æ—¶é—´"
        }
        
        # ç­›é€‰2026å±Šç›¸å…³èŒä½
        filtered_jobs = [job for job in job_list if is_target_recruitment(job.get("target", ""))]
        df = pd.DataFrame(filtered_jobs).rename(columns=CN_HEADERS)
        
        # æ ‡è®°æ–°å¢èŒä½
        if added_jobs:
            valid_added_ids = {f"{j['company']}-{j['position']}" for j in added_jobs 
                              if is_target_recruitment(j.get("target", ""))}
            df['_is_new'] = df.apply(
                lambda x: "æ˜¯" if f"{x['å…¬å¸åç§°']}-{x['èŒä½åç§°']}" in valid_added_ids else "å¦", 
                axis=1
            )
        
        # å†™å…¥Excelå¹¶é«˜äº®æ–°å¢èŒä½
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='æ‹›è˜ä¿¡æ¯')
            worksheet = writer.sheets['æ‹›è˜ä¿¡æ¯']
            
            # é«˜äº®å¤„ç†
            if added_jobs and len(valid_added_ids) > 0:
                yellow_fill = openpyxl.styles.PatternFill(start_color="FFFF00", fill_type="solid")
                for row in worksheet.iter_rows(min_row=2):
                    if row[-1].value == "æ˜¯":
                        for cell in row[:-1]:
                            cell.fill = yellow_fill
                worksheet.delete_cols(worksheet.max_column)  # åˆ é™¤æ ‡è®°åˆ—
            
            # è°ƒæ•´åˆ—å®½
            for col in worksheet.columns:
                max_len = max(len(str(cell.value)) for cell in col)
                worksheet.column_dimensions[col[0].column_letter].width = min(max_len + 2, 30)
        
        logger.info(f"Excelå·²ä¿å­˜è‡³ {filename}ï¼ŒåŒ…å« {len(filtered_jobs)} æ¡2026å±Šç›¸å…³èŒä½")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜Excelå¤±è´¥: {e}")
        return False


def generate_email_html(new_jobs, job_type):
    """ç”Ÿæˆç¾åŒ–çš„HTMLé‚®ä»¶å†…å®¹
    
    å‚æ•°:
        new_jobs: æ–°å¢èŒä½åˆ—è¡¨
        job_type: èŒä½ç±»å‹ï¼ˆæ ¡æ‹›/å®ä¹ ï¼‰
        
    è¿”å›:
        str: HTMLæ ¼å¼çš„é‚®ä»¶å†…å®¹
    """
    # ç­›é€‰2026å±Šç›¸å…³èŒä½
    filtered_jobs = [job for job in new_jobs if is_target_recruitment(job.get("target", ""))]
    
    # CSSæ ·å¼ï¼ˆç¾åŒ–é‚®ä»¶ï¼‰
    styles = """
    <style>
        body { font-family: 'Segoe UI', sans-serif; line-height: 1.6; color: #333; max-width: 800px; margin: 0 auto; padding: 20px; background: #f5f7fa; }
        .header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); color: white; padding: 20px; border-radius: 8px 8px 0 0; text-align: center; margin-bottom: 25px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .header h1 { margin: 0; font-weight: 600; font-size: 24px; }
        .notification-card { background: white; border-radius: 8px; padding: 30px; margin-bottom: 30px; box-shadow: 0 4px 15px rgba(0,0,0,0.08); border: 1px solid #eaeaea; }
        .stats { display: flex; justify-content: space-around; margin-bottom: 25px; text-align: center; }
        .stat-item { background: #f0f5ff; padding: 15px; border-radius: 8px; flex: 1; margin: 0 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
        .stat-item span { display: block; font-size: 28px; font-weight: bold; color: #4b6cb7; margin-bottom: 5px; }
        .job-item { background: #fff; border-left: 4px solid #4b6cb7; margin-bottom: 15px; padding: 15px; border-radius: 0 6px 6px 0; transition: all 0.3s ease; }
        .job-item:hover { transform: translateY(-3px); box-shadow: 0 5px 15px rgba(75, 108, 183, 0.15); }
        .company { font-weight: bold; color: #2c3e50; font-size: 18px; margin-bottom: 5px; }
        .position { font-weight: 600; color: #4b6cb7; font-size: 16px; margin: 10px 0; }
        .meta { display: flex; flex-wrap: wrap; gap: 15px; margin: 10px 0; color: #555; font-size: 14px; }
        .meta span:before { content: "â€¢"; margin-right: 5px; color: #4b6cb7; }
        .deadline { background: #fff9e6; color: #e67e22; padding: 5px 10px; border-radius: 4px; font-weight: 600; display: inline-block; margin-top: 5px; }
        .target-highlight { background: #e3f2fd; color: #0d47a1; padding: 2px 5px; border-radius: 3px; font-weight: 500; }
        .links a { display: inline-block; background: #4b6cb7; color: white; text-decoration: none; padding: 8px 15px; border-radius: 4px; margin-top: 10px; transition: background 0.3s; }
        .links a:hover { background: #3a559f; }
        .notes { margin-top: 10px; padding: 10px; background: #f8f9fa; border-left: 3px solid #4b6cb7; font-size: 14px; color: #555; }
        .footer { text-align: center; margin-top: 30px; color: #777; font-size: 13px; padding: 15px; border-top: 1px solid #eee; }
    </style>
    """
    
    # æ„å»ºHTMLå†…å®¹
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>æ–°èŒä½é€šçŸ¥ - {job_type}</title>
        {styles}
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¯ æ–°èŒä½é€šçŸ¥ - {job_type} (2026å±Šç›¸å…³)</h1>
        </div>
        
        <div class="notification-card">
            <div class="stats">
                <div class="stat-item">
                    <span>{len(filtered_jobs)}</span>
                    æ–°èŒä½
                </div>
                <div class="stat-item">
                    <span>{len(set(job['company'] for job in filtered_jobs))}</span>
                    å®¶å…¬å¸
                </div>
                <div class="stat-item">
                    <span>{datetime.now().strftime('%m/%d')}</span>
                    æ›´æ–°æ—¥æœŸ
                </div>
            </div>
            
            <div class="job-list">
    """
    
    # æ·»åŠ èŒä½åˆ—è¡¨
    for job in filtered_jobs:
        deadline = job.get('deadline', 'æˆªæ­¢æ—¶é—´å¾…å®š')
        target = job.get('target', '')
        links_html = f'<div class="links"><a href="{job["links"]}" target="_blank">æŸ¥çœ‹èŒä½è¯¦æƒ…</a></div>' if job.get('links') else ""
        notes = f'<div class="notes">ğŸ’¡ èŒä½äº®ç‚¹: {html.escape(job.get("notes", ""))}</div>' if job.get('notes') else ""
        
        html_content += f"""
        <div class="job-item">
            <div class="company">{html.escape(job.get('company', ''))}</div>
            <div class="position">ğŸ¢ {html.escape(job.get('position', ''))}</div>
            <div class="meta">
                <span>ğŸ“ {html.escape(job.get('location', ''))}</span>
                <span>ğŸš€ {html.escape(job.get('recruitment_type', ''))}</span>
                <span>ğŸ¯ <span class="target-highlight">{html.escape(target)}</span></span>
            </div>
            <div class="deadline">â° æˆªæ­¢æ—¶é—´: {html.escape(str(deadline))}</div>
            {notes}
            {links_html}
        </div>
        """
    
    # æ— æ–°èŒä½æç¤º
    if not filtered_jobs:
        html_content += """
        <div class="no-jobs">
            <p>æœ¬æ¬¡æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æ–°èŒä½ï¼ˆä»…é™2026å±Šç›¸å…³ï¼‰ã€‚</p>
        </div>
        """
    
    # é‚®ä»¶åº•éƒ¨
    html_content += f"""
            </div>
        </div>
        <div class="footer">
            <p>è‡ªåŠ¨çˆ¬è™«ç³»ç»Ÿç”Ÿæˆ | æŠ“å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>Â© {datetime.now().year} èŒä½ç›‘æ§ç³»ç»Ÿ | å…±å‘ç° {len(filtered_jobs)} ä¸ª2026å±Šç›¸å…³æ–°èŒä½</p>
        </div>
    </body>
    </html>
    """
    return html_content


def send_email(subject, body, attachment_paths=None):
    """å‘é€é‚®ä»¶é€šçŸ¥
    
    å‚æ•°:
        subject: é‚®ä»¶ä¸»é¢˜
        body: é‚®ä»¶å†…å®¹ï¼ˆHTMLæ ¼å¼ï¼‰
        attachment_paths: é™„ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
    è¿”å›:
        bool: å‘é€æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™False
    """
    try:
        # æ£€æŸ¥é‚®ç®±é…ç½®
        if not EMAIL_USER or not EMAIL_PWD or not RECEIVER_EMAILS:
            logger.warning("é‚®ç®±é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å‘é€")
            return False
            
        # é‚®ä»¶æœåŠ¡å™¨é…ç½®ï¼ˆQQé‚®ç®±ç¤ºä¾‹ï¼‰
        smtp_server = "smtp.qq.com"
        smtp_port = 587

        # æ„å»ºé‚®ä»¶
        msg = MIMEMultipart()
        msg['From'] = EMAIL_USER
        msg['To'] = ", ".join(RECEIVER_EMAILS)
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'html'))

        # æ·»åŠ é™„ä»¶
        if attachment_paths:
            for path in attachment_paths:
                if os.path.exists(path):
                    with open(path, 'rb') as f:
                        part = MIMEApplication(f.read(), Name=os.path.basename(path))
                    part['Content-Disposition'] = f'attachment; filename="{os.path.basename(path)}"'
                    msg.attach(part)

        # å‘é€é‚®ä»¶
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PWD)
            server.sendmail(EMAIL_USER, RECEIVER_EMAILS, msg.as_string())
        
        logger.info(f"é‚®ä»¶å·²å‘é€è‡³: {', '.join(RECEIVER_EMAILS)}")
        return True
    except Exception as e:
        logger.error(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")
        return False


# ============================
# æµç¨‹æ§åˆ¶å‡½æ•°
# ============================

def process_site(site_name, site_url, data_file, excel_file):
    """å¤„ç†å•ä¸ªç«™ç‚¹çš„å®Œæ•´çˆ¬å–æµç¨‹
    
    å‚æ•°:
        site_name: ç«™ç‚¹åç§°ï¼ˆæ ¡æ‹›/å®ä¹ ï¼‰
        site_url: ç«™ç‚¹URL
        data_file: æ•°æ®å­˜å‚¨JSONè·¯å¾„
        excel_file: Excelè¾“å‡ºè·¯å¾„
        
    è¿”å›:
        list: æ‰€æœ‰æœ‰æ•ˆèŒä½åˆ—è¡¨ï¼ˆ2026å±Šç›¸å…³ï¼‰
    """
    logger.info(f"å¼€å§‹å¤„ç† {site_name} ç«™ç‚¹ï¼ˆ{START_PAGE}-{END_PAGE}é¡µï¼Œæ¯æ¬¡{MAX_PAGES_PER_SESSION}é¡µï¼‰")
    
    # åŠ è½½å†å²æ•°æ®
    historical_data = load_and_clean_historical_data(data_file)
    existing_jobs = historical_data.get("jobs", {})
    all_new_jobs = []  # ç´¯è®¡æ‰€æœ‰æ–°èŒä½
    
    # åˆ†é¡µçˆ¬å–ï¼ˆæ¯æ¬¡ä¼šè¯çˆ¬å–2é¡µï¼Œé¿å…è¢«åçˆ¬ï¼‰
    current_start_page = START_PAGE
    while current_start_page <= END_PAGE:
        # æ¯æ¬¡ä¼šè¯é‡æ–°åˆå§‹åŒ–æµè§ˆå™¨
        driver = setup_browser()
        
        # è®¡ç®—å½“å‰ä¼šè¯çˆ¬å–èŒƒå›´
        current_end_page = min(current_start_page + MAX_PAGES_PER_SESSION - 1, END_PAGE)
        logger.info(f"=== çˆ¬å– {current_start_page}-{current_end_page} é¡µ ===")
        
        # è°ƒç”¨å¯¹åº”çˆ¬è™«å‡½æ•°
        if site_name == "æ ¡æ‹›":
            new_jobs, last_page = crawl_campus_data(driver, site_url, current_start_page, current_end_page)
        else:
            new_jobs, last_page = crawl_internship_data(driver, site_url, current_start_page, current_end_page)
        
        # å…³é—­æµè§ˆå™¨
        driver.quit()
        
        # å¤„ç†æ–°èŒä½
        for job in new_jobs:
            job_id = f"{job['company']}-{job['position']}"  # ç”Ÿæˆå”¯ä¸€ID
            if job_id not in existing_jobs:
                all_new_jobs.append(job)
                existing_jobs[job_id] = job
                logger.info(f"å‘ç°æ–°èŒä½: {job['company']} - {job['position']}")
        
        # æ›´æ–°ä¸‹ä¸€è½®èµ·å§‹é¡µ
        current_start_page = last_page + 1
        logger.info(f"=== å®Œæˆ {current_start_page - MAX_PAGES_PER_SESSION}-{last_page} é¡µçˆ¬å– ===")
        
        # çˆ¬å–é—´éš”ï¼ˆååçˆ¬ï¼‰
        if current_start_page <= END_PAGE:
            sleep_time = random.uniform(5, 10)
            logger.info(f"ç­‰å¾… {sleep_time:.1f} ç§’åç»§ç»­çˆ¬å–...")
            time.sleep(sleep_time)
    
    # æ›´æ–°å¹¶ä¿å­˜å†å²æ•°æ®
    historical_data["jobs"] = existing_jobs
    historical_data["last_update"] = datetime.now().isoformat()
    historical_data = clean_expired_jobs(historical_data)  # æ¸…ç†è¿‡æœŸèŒä½
    save_historical_data(historical_data, data_file)
    
    # ç”ŸæˆExcelå¹¶å‘é€é€šçŸ¥
    logger.info(f"{site_name} çˆ¬å–å®Œæˆï¼Œæ–°å¢ {len(all_new_jobs)} ä¸ª2026å±Šç›¸å…³èŒä½")
    if save_excel_file(list(existing_jobs.values()), excel_file, added_jobs=all_new_jobs):
        email_body = generate_email_html(all_new_jobs, site_name)
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–°ï¼ˆ2026å±Šç›¸å…³ï¼‰- {datetime.now().strftime('%Y%m%d')}",
            body=email_body,
            attachment_paths=[excel_file]
        )
    else:
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–°ï¼ˆ2026å±Šç›¸å…³ï¼‰- {datetime.now().strftime('%Y%m%d')}",
            body=f"<h3>{site_name}çˆ¬å–å®Œæˆ</h3><p>2026å±Šç›¸å…³æ–°èŒä½: {len(all_new_jobs)} ä¸ª</p><p>Excelç”Ÿæˆå¤±è´¥</p>"
        )
    
    return list(existing_jobs.values())


# ============================
# ä¸»å‡½æ•°
# ============================

def main():
    """ç¨‹åºå…¥å£å‡½æ•°"""
    logger.info(f"===== å¼€å§‹æ‹›è˜ä¿¡æ¯çˆ¬å–ä»»åŠ¡ =====")
    logger.info(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ç›®æ ‡èŒƒå›´: {START_PAGE}-{END_PAGE}é¡µï¼Œç­›é€‰2026å±Šç›¸å…³èŒä½")
    
    try:
        # çˆ¬å–æ ¡æ‹›ä¿¡æ¯
        campus_data = process_site(
            "æ ¡æ‹›",
            SITE_URL,
            DATA_FILE_CAMPUS,
            EXCEL_FILE_CAMPUS
        )
        
        # çˆ¬å–å®ä¹ ä¿¡æ¯
        intern_data = process_site(
            "å®ä¹ ",
            SITE_URL_INTERNSHIP,
            DATA_FILE_INTERNSHIP,
            EXCEL_FILE_INTERNSHIP
        )
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        logger.info(f"æ ¡æ‹›2026å±Šç›¸å…³èŒä½æ€»æ•°: {len(campus_data)}")
        logger.info(f"å®ä¹ 2026å±Šç›¸å…³èŒä½æ€»æ•°: {len(intern_data)}")
        logger.info("===== æ‰€æœ‰ä»»åŠ¡å®Œæˆ =====")
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºé”™è¯¯: {e}")
        # å‘é€é”™è¯¯é€šçŸ¥
        send_email(
            subject="æ‹›è˜çˆ¬å–å‡ºé”™é€šçŸ¥",
            body=f"<h2>çˆ¬å–å¤±è´¥</h2><p>é”™è¯¯: {str(e)}</p><p>æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>"
        )


if __name__ == "__main__":
    main()
