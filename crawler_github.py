import os
import time
import json
import logging
import smtplib
import random
import pandas as pd
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from fake_useragent import UserAgent
import openpyxl
import html

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# é…ç½®å¸¸é‡
START_PAGE = 1
END_PAGE = 6
MAX_PAGES_PER_SESSION = 2
SITE_URL = "https://www.givemeoc.com"  # æ ¡æ‹›å²—ä½
SITE_URL_INTERNSHIP = "https://www.givemeoc.com/internship"  # å®ä¹ å²—ä½
WAIT_TIME_MIN = 1
WAIT_TIME_MAX = 3

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
EMAIL_USER = os.environ.get('EMAIL_USER')  # å‘é€é‚®ç®±
EMAIL_PWD = os.environ.get('EMAIL_PWD')  # å‘é€é‚®ç®±å¯†ç 
RECEIVER_EMAILS = os.environ.get('RECEIVER_EMAILS').split(';')  # å¤šä¸ªæ¥æ”¶é‚®ç®±ï¼ˆåˆ†å·åˆ†éš”ï¼‰

# ä¸ºä¸¤ç±»å²—ä½åˆ›å»ºç‹¬ç«‹çš„å­˜å‚¨æ–‡ä»¶
DATA_FILE_CAMPUS = "campus_jobs.json"  # æ ¡æ‹›æ•°æ®æ–‡ä»¶
DATA_FILE_INTERNSHIP = "intern_jobs.json"  # å®ä¹ æ•°æ®æ–‡ä»¶
EXCEL_FILE_CAMPUS = "campus_jobs.xlsx"  # æ ¡æ‹›Excel
EXCEL_FILE_INTERNSHIP = "intern_jobs.xlsx"  # å®ä¹ Excel

def setup_browser():
    """é…ç½®æµè§ˆå™¨ï¼ˆGitHub Actionsä¸“ç”¨ï¼‰"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument("--incognito")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    
    # å…³é”®ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šChromiumè·¯å¾„
    chrome_options.binary_location = "/usr/bin/chromium-browser"
    
    # éšæœºUser-Agent
    ua = UserAgent()
    chrome_options.add_argument(f"user-agent={ua.random}")
    
    # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
    driver = webdriver.Chrome(options=chrome_options)
    
    # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'
    })
    
    logger.info(f"æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è·¯å¾„: {chrome_options.binary_location}")
    return driver

def crawl_campus_data(driver, site_url, start_page, end_page):
    """
    ä¸“é—¨çˆ¬å–æ ¡æ‹›ç«™ç‚¹æ•°æ®
    æ³¨æ„ï¼šä»¥ä¸‹é€‰æ‹©å™¨éœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´
    """
    try:
        # è®¿é—®æ ¡æ‹›ç½‘ç«™
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # å¦‚æœèµ·å§‹é¡µä¸æ˜¯ç¬¬ä¸€é¡µï¼Œè·³è½¬åˆ°æŒ‡å®šé¡µ
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°ç¬¬ {start_page} é¡µ...")
                # TODO: æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                page_input = driver.find_element("css selector", "input.crt-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))

                # TODO: æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)
                time.sleep(random.gauss(3, 1))
            except Exception as e:
                logger.error(f"è·³è½¬åˆ°ç¬¬ {start_page} é¡µæ—¶å‡ºé”™: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # çˆ¬å–æŒ‡å®šé¡µæ•°çš„æ•°æ®
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"æ­£åœ¨çˆ¬å–æ ¡æ‹›ç¬¬ {page} é¡µ...")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£ææ•°æ® - TODO: æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
            job_items = driver.find_elements("css selector", "table.crt-table tbody tr")

            for item in job_items:
                try:
                    # ä»¥ä¸‹é€‰æ‹©å™¨éœ€è¦æ ¹æ®å®é™…æ ¡æ‹›é¡µé¢ç»“æ„è°ƒæ•´
                    company = safe_get_text(item, "td.crt-col-company")
                    company_type = safe_get_text(item, "td.crt-col-type")
                    location = safe_get_text(item, "td.crt-col-location")
                    recruitment_type = safe_get_text(item, "td.crt-col-recruitment-type")
                    target = safe_get_text(item, "td.crt-col-target")
                    position = safe_get_text(item, "td.crt-col-position")
                    update_time = safe_get_text(item, "td.crt-col-update-time")
                    deadline = safe_get_text(item, "td.crt-col-deadline")
                    links = safe_get_attr(item, "td.crt-col-links a", "href")
                    notice = safe_get_attr(item, "td.crt-col-notice a", "href")
                    referral = safe_get_text(item, "td.crt-col-referral")
                    notes = safe_get_text(item, "td.crt-col-notes")

                    crawled_data.append({
                        "job_type": "æ ¡æ‹›",  # å›ºå®šä¸ºæ ¡æ‹›ç±»å‹
                        "company": company,
                        "company_type": company_type,
                        "location": location,
                        "recruitment_type": recruitment_type,
                        "target": target,
                        "position": position,
                        "update_time": update_time,
                        "deadline": deadline,
                        "links": links,
                        "notice": notice,
                        "referral": referral,
                        "notes": notes,
                        "crawl_time": datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†æ ¡æ‹›æ•°æ®è¡Œæ—¶å‡ºé”™: {e}")
                    continue

            # æ ¡æ‹›ç¿»é¡µé€»è¾‘
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    # TODO: æ ¹æ®å®é™…æ ¡æ‹›é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                    page_input = driver.find_element("css selector", "input.crt-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))

                    # TODO: æ ¹æ®å®é™…æ ¡æ‹›é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                    go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                    
                    # æ›´æ–°User-Agent
                    new_ua = UserAgent().random
                    driver.execute_script(f"navigator.userAgent = '{new_ua}';")
                except Exception as e:
                    logger.warning(f"æ ¡æ‹›ç¿»é¡µæ—¶å‡ºé”™ï¼Œå¯èƒ½å·²åˆ°è¾¾æœ€åä¸€é¡µ: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"çˆ¬å–æ ¡æ‹›æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return [], start_page

def crawl_internship_data(driver, site_url, start_page, end_page):
    """
    ä¸“é—¨çˆ¬å–å®ä¹ ç«™ç‚¹æ•°æ®
    æ³¨æ„ï¼šä»¥ä¸‹é€‰æ‹©å™¨éœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´
    """
    try:
        # è®¿é—®å®ä¹ ç½‘ç«™
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # å¦‚æœèµ·å§‹é¡µä¸æ˜¯ç¬¬ä¸€é¡µï¼Œè·³è½¬åˆ°æŒ‡å®šé¡µ
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°ç¬¬ {start_page} é¡µ...")
                # TODO: æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                page_input = driver.find_element("css selector", "input.int-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))

                # TODO: æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                go_button = driver.find_element("css selector", "button.int-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)
                time.sleep(random.gauss(3, 1))
            except Exception as e:
                logger.error(f"è·³è½¬åˆ°ç¬¬ {start_page} é¡µæ—¶å‡ºé”™: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # çˆ¬å–æŒ‡å®šé¡µæ•°çš„æ•°æ®
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"æ­£åœ¨çˆ¬å–å®ä¹ ç¬¬ {page} é¡µ...")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£ææ•°æ® - TODO: æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
            job_items = driver.find_elements("css selector", "table.int-table tbody tr")

            for item in job_items:
                try:
                    # ä»¥ä¸‹é€‰æ‹©å™¨éœ€è¦æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´
                    company = safe_get_text(item, "td.int-col-company")
                    company_type = safe_get_text(item, "td.int-col-type")
                    location = safe_get_text(item, "td.int-col-location")
                    recruitment_type = safe_get_text(item, "td.int-col-recruitment-type")
                    target = safe_get_text(item, "td.int-col-target")
                    position = safe_get_text(item, "td.int-col-position")
                    update_time = safe_get_text(item, "td.int-col-update-time")
                    deadline = safe_get_text(item, "td.int-col-deadline")
                    links = safe_get_attr(item, "td.int-col-links a", "href")
                    notice = safe_get_attr(item, "td.int-col-notice a", "href")
                    referral = safe_get_text(item, "td.int-col-referral")
                    notes = safe_get_text(item, "td.int-col-notes")

                    crawled_data.append({
                        "job_type": "å®ä¹ ",  # å›ºå®šä¸ºå®ä¹ ç±»å‹
                        "company": company,
                        "company_type": company_type,
                        "location": location,
                        "recruitment_type": recruitment_type,
                        "target": target,
                        "position": position,
                        "update_time": update_time,
                        "deadline": deadline,
                        "links": links,
                        "notice": notice,
                        "referral": referral,
                        "notes": notes,
                        "crawl_time": datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†å®ä¹ æ•°æ®è¡Œæ—¶å‡ºé”™: {e}")
                    continue

            # å®ä¹ ç¿»é¡µé€»è¾‘
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    # TODO: æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                    page_input = driver.find_element("css selector", "input.int-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))

                    # TODO: æ ¹æ®å®é™…å®ä¹ é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                    go_button = driver.find_element("css selector", "button.int-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                    
                    # æ›´æ–°User-Agent
                    new_ua = UserAgent().random
                    driver.execute_script(f"navigator.userAgent = '{new_ua}';")
                except Exception as e:
                    logger.warning(f"å®ä¹ ç¿»é¡µæ—¶å‡ºé”™ï¼Œå¯èƒ½å·²åˆ°è¾¾æœ€åä¸€é¡µ: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"çˆ¬å–å®ä¹ æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return [], start_page

def safe_get_text(element, selector):
    """å®‰å…¨è·å–å…ƒç´ æ–‡æœ¬"""
    try:
        return element.find_element("css selector", selector).text
    except:
        return ""

def safe_get_attr(element, selector, attribute):
    """å®‰å…¨è·å–å…ƒç´ å±æ€§"""
    try:
        return element.find_element("css selector", selector).get_attribute(attribute)
    except:
        return ""

def load_historical_data(data_file):
    """ä»æŒ‡å®šæ–‡ä»¶åŠ è½½å†å²æ•°æ®"""
    try:
        logger.info(f"åŠ è½½å†å²æ•°æ®: {data_file}")
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            logger.info(f"é¦–æ¬¡è¿è¡Œï¼šå°šæœªæ‰¾åˆ°å†å²æ•°æ®æ–‡ä»¶ {data_file}")
            return {
                "last_update": None,
                "jobs": {}
            }
    except Exception as e:
        logger.warning(f"åŠ è½½å†å²æ•°æ®å¤±è´¥: {str(e)}ï¼Œå°†åˆ›å»ºæ–°æ•°æ®é›†")
        return {
            "last_update": None,
            "jobs": {}
        }

def save_historical_data(data, data_file):
    """ä¿å­˜æ•°æ®åˆ°æŒ‡å®šæ–‡ä»¶"""
    try:
        logger.info(f"ä¿å­˜æ•°æ®åˆ°æœ¬åœ°: {data_file}")
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"æˆåŠŸä¿å­˜æ•°æ®åˆ°: {data_file}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {str(e)}")
        return False

def save_excel_file(job_list, filename, added_jobs=None):
    """ä¿å­˜Excelæ–‡ä»¶ï¼ˆè‡ªåŠ¨ä¸­æ–‡è¡¨å¤´+é«˜äº®æ–°å¢ï¼‰"""
    try:
        # --- 1. ä¸­æ–‡åˆ—åæ˜ å°„ ---
        CN_HEADERS = {
            "company": "å…¬å¸åç§°",
            "company_type": "å…¬å¸ç±»å‹",
            "location": "å·¥ä½œåœ°ç‚¹",
            "recruitment_type": "æ‹›è˜ç±»å‹",
            "target": "æ‹›è˜å¯¹è±¡",
            "position": "èŒä½åç§°",
            "update_time": "æ›´æ–°æ—¶é—´",
            "deadline": "æˆªæ­¢æ—¶é—´",
            "links": "èŒä½é“¾æ¥",
            "notice": "é€šçŸ¥é“¾æ¥",
            "referral": "å†…æ¨ä¿¡æ¯",
            "notes": "å¤‡æ³¨",
            "crawl_time": "çˆ¬å–æ—¶é—´"
        }
        
        # --- 2. å¤„ç†æ•°æ® ---
        # åˆ›å»ºDataFrameå¹¶é‡å‘½ååˆ—
        df = pd.DataFrame(job_list).rename(columns=CN_HEADERS)
        
        # æ ‡è®°æ–°å¢èŒä½ï¼ˆä¸´æ—¶åˆ—ï¼Œå®Œæˆååˆ é™¤ï¼‰
        if added_jobs:
            added_ids = {f"{j['company']}-{j['position']}" for j in added_jobs}
            df['_is_new'] = df.apply(
                lambda x: "æ˜¯" if f"{x['å…¬å¸åç§°']}-{x['èŒä½åç§°']}" in added_ids else "å¦", 
                axis=1
            )
        
        # --- 3. ä¿å­˜Excel ---
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='æ‹›è˜ä¿¡æ¯')
            
            # è·å–å·¥ä½œè¡¨å¯¹è±¡
            worksheet = writer.sheets['æ‹›è˜ä¿¡æ¯']
            
            # --- 4. é«˜äº®æ–°å¢èŒä½ ---
            if added_jobs:
                from openpyxl.styles import PatternFill
                yellow_fill = PatternFill(start_color="FFFF00", fill_type="solid")
                
                for row in worksheet.iter_rows(min_row=2):
                    if row[-1].value == "æ˜¯":  # æœ€åä¸€åˆ—æ˜¯ä¸´æ—¶æ ‡è®°åˆ—
                        for cell in row[:-1]:  # ä¸å¤„ç†æ ‡è®°åˆ—æœ¬èº«
                            cell.fill = yellow_fill
                
                # åˆ é™¤ä¸´æ—¶åˆ—
                worksheet.delete_cols(worksheet.max_column)
            
            # --- 5. è°ƒæ•´åˆ—å®½ ---
            for col in worksheet.columns:
                max_len = max(len(str(cell.value)) for cell in col)
                worksheet.column_dimensions[col[0].column_letter].width = min(max_len + 2, 30)
        
        logger.info(f"Excelæ–‡ä»¶å·²ä¿å­˜: {filename}")
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜Excelå¤±è´¥: {str(e)}")
        return False
        
def clean_expired_jobs(historical_data):
    """æ¸…ç†è¿‡æœŸèŒä½ï¼ˆå‡è®¾å†å²æ•°æ®ä¸­çš„æ¯ä¸ªèŒä½éƒ½æœ‰deadlineå­—æ®µï¼‰"""
    logger.info("å¼€å§‹æ¸…ç†è¿‡æœŸèŒä½...")
    current_time = datetime.now()
    expired_count = 0
    # éå†å†å²æ•°æ®ä¸­çš„èŒä½
    for job_id, job in list(historical_data['jobs'].items()):
        # å¦‚æœdeadlineå­˜åœ¨ä¸”å·²è¿‡æœŸ
        if job.get('deadline'):
            # å°è¯•è§£ædeadlineå­—ç¬¦ä¸²ä¸ºæ—¥æœŸå¯¹è±¡
            try:
                # å‡è®¾deadlineæ ¼å¼ä¸º"YYYY-MM-DD"
                deadline_date = datetime.strptime(job['deadline'], "%Y-%m-%d")
                if deadline_date < current_time:
                    del historical_data['jobs'][job_id]
                    expired_count += 1
                    logger.info(f"å·²åˆ é™¤åˆ°æœŸèŒä½: {job['company']} - {job['position']} (æˆªæ­¢æ—¶é—´: {job['deadline']})")
            except Exception as e:
                logger.warning("æ‹›æ»¡å³æ­¢")
                continue
    logger.info(f"æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {expired_count} ä¸ªè¿‡æœŸèŒä½")
    return historical_data


# æ·»åŠ ç”Ÿæˆç²¾ç¾HTMLé‚®ä»¶çš„å‡½æ•°
def generate_email_html(new_jobs, job_type):
    """ç”Ÿæˆç¾è§‚çš„HTMLé‚®ä»¶å†…å®¹"""
    # CSSæ ·å¼
    styles = """
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            line-height: 1.6; 
            color: #333; 
            max-width: 800px; 
            margin: 0 auto; 
            padding: 20px; 
            background-color: #f5f7fa; 
        }
        .header { 
            background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%);
            color: white; 
            padding: 20px; 
            border-radius: 8px 8px 0 0;
            text-align: center;
            margin-bottom: 25px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .header h1 { 
            margin: 0; 
            font-weight: 600;
            font-size: 24px;
        }
        .notification-card {
            background: white;
            border-radius: 8px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.08);
            border: 1px solid #eaeaea;
        }
        .stats {
            display: flex;
            justify-content: space-around;
            margin-bottom: 25px;
            text-align: center;
        }
        .stat-item {
            background: #f0f5ff;
            padding: 15px;
            border-radius: 8px;
            flex: 1;
            margin: 0 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .stat-item span {
            display: block;
            font-size: 28px;
            font-weight: bold;
            color: #4b6cb7;
            margin-bottom: 5px;
        }
        .job-list {
            border-collapse: collapse;
            width: 100%;
        }
        .job-item {
            background-color: #fff;
            border-left: 4px solid #4b6cb7;
            margin-bottom: 15px;
            padding: 15px;
            border-radius: 0 6px 6px 0;
            transition: all 0.3s ease;
        }
        .job-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(75, 108, 183, 0.15);
        }
        .company {
            font-weight: bold;
            color: #2c3e50;
            font-size: 18px;
            margin-bottom: 5px;
        }
        .position {
            font-weight: 600;
            color: #4b6cb7;
            font-size: 16px;
            margin: 10px 0;
        }
        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin: 10px 0;
            color: #555;
            font-size: 14px;
        }
        .meta span {
            display: flex;
            align-items: center;
        }
        .meta span:before {
            content: "â€¢";
            margin-right: 5px;
            color: #4b6cb7;
        }
        .deadline {
            background-color: #fff9e6;
            color: #e67e22;
            padding: 5px 10px;
            border-radius: 4px;
            font-weight: 600;
            display: inline-block;
            margin-top: 5px;
        }
        .links a {
            display: inline-block;
            background: #4b6cb7;
            color: white !important;
            text-decoration: none;
            padding: 8px 15px;
            border-radius: 4px;
            margin-top: 10px;
            font-weight: 500;
            transition: background 0.3s;
        }
        .links a:hover {
            background: #3a559f;
            text-decoration: none;
        }
        .notes {
            margin-top: 10px;
            padding: 10px;
            background-color: #f8f9fa;
            border-left: 3px solid #4b6cb7;
            font-size: 14px;
            color: #555;
        }
        .footer {
            text-align: center;
            margin-top: 30px;
            color: #777;
            font-size: 13px;
            padding: 15px;
            border-top: 1px solid #eee;
        }
        .highlight {
            background: linear-gradient(120deg, #e0f7fa 0%, #bbdefb 100%);
            padding: 2px 5px;
            border-radius: 3px;
        }
    </style>
    """
    
    # æ„å»ºHTMLå†…å®¹
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>æ–°èŒä½é€šçŸ¥ - {job_type}</title>
        {styles}
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¯ æ–°èŒä½é€šçŸ¥ - {job_type}</h1>
        </div>
        
        <div class="notification-card">
            <div class="stats">
                <div class="stat-item">
                    <span>{len(new_jobs)}</span>
                    æ–°èŒä½
                </div>
                <div class="stat-item">
                    <span>{len(set(job['company'] for job in new_jobs))}</span>
                    å®¶å…¬å¸
                </div>
                <div class="stat-item">
                    <span>{datetime.now().strftime('%m/%d')}</span>
                    æ›´æ–°æ—¥æœŸ
                </div>
            </div>
            
            <div class="job-list">
    """
    
    # æ·»åŠ æ¯ä¸ªèŒä½çš„ä¿¡æ¯
    for job in new_jobs:
        deadline = job.get('deadline', 'æˆªæ­¢æ—¶é—´å¾…å®š')
        links_html = ""
        if job.get('links'):
            links_html = f'<div class="links"><a href="{job["links"]}" target="_blank">æŸ¥çœ‹èŒä½è¯¦æƒ…</a></div>'
        
        # å¤„ç†èŒä½äº®ç‚¹
        notes = job.get('notes', '')
        if notes:
            notes = f'<div class="notes">ğŸ’¡ èŒä½äº®ç‚¹: {html.escape(notes)}</div>'
        
        html_content += f"""
        <div class="job-item">
            <div class="company">{html.escape(job.get('company', ''))}</div>
            <div class="position">ğŸ¢ {html.escape(job.get('position', ''))}</div>
            <div class="meta">
                <span>ğŸ“ {html.escape(job.get('location', ''))}</span>
                <span>ğŸš€ {html.escape(job.get('recruitment_type', ''))}</span>
                <span>ğŸ¯ {html.escape(job.get('target', ''))}</span>
            </div>
            <div class="deadline">â° æˆªæ­¢æ—¶é—´: {html.escape(str(deadline))}</div>
            {notes}
            {links_html}
        </div>
        """
    
    # é¡µè„š
    html_content += f"""
            </div>
        </div>
        
        <div class="footer">
            <p>æ­¤é‚®ä»¶ç”±è‡ªåŠ¨çˆ¬è™«ç³»ç»Ÿç”Ÿæˆ | æŠ“å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>Â© {datetime.now().year} èŒä½ç›‘æ§ç³»ç»Ÿ | å…±å‘ç° {len(new_jobs)} ä¸ªæ–°èŒä½</p>
        </div>
    </body>
    </html>
    """
    
    return html_content
        
def send_email(subject, body, attachment_paths=None):
    """
    å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆæ”¯æŒå¤šé™„ä»¶å’Œå¤šæ¥æ”¶é‚®ç®±ï¼‰
    :param subject: é‚®ä»¶ä¸»é¢˜
    :param body: é‚®ä»¶æ­£æ–‡å†…å®¹
    :param attachment_paths: é™„ä»¶è·¯å¾„åˆ—è¡¨(å¯é€‰)
    :return: å‘é€æ˜¯å¦æˆåŠŸ
    """
    try:
        smtp_server = "smtp.qq.com"
        smtp_port = 587

        msg = MIMEMultipart()
        msg['From'] = EMAIL_USER
        msg['To'] = ", ".join(RECEIVER_EMAILS)
        msg['Subject'] = subject
        
        # æ·»åŠ HTMLæ ¼å¼çš„é‚®ä»¶æ­£æ–‡
        msg.attach(MIMEText(body, 'html'))

        # æ·»åŠ é™„ä»¶
        if attachment_paths:
            for path in attachment_paths:
                if os.path.exists(path):
                    with open(path, 'rb') as f:
                        part = MIMEApplication(f.read(), Name=os.path.basename(path))
                    part['Content-Disposition'] = f'attachment; filename="{os.path.basename(path)}"'
                    msg.attach(part)

        # å‘é€é‚®ä»¶
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PWD)
            server.sendmail(EMAIL_USER, RECEIVER_EMAILS, msg.as_string())
        
        logger.info(f"é‚®ä»¶å·²å‘é€è‡³: {', '.join(RECEIVER_EMAILS)}")
        return True
    except Exception as e:
        logger.error(f"é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")
        return False

def process_site(site_name, site_url, data_file, excel_file):
    """å¤„ç†å•ä¸ªç«™ç‚¹çš„çˆ¬å–å’Œæ›´æ–°é€»è¾‘"""
    logger.info(f"å¤„ç†ç«™ç‚¹: {site_name}")
    
    # åˆå§‹åŒ–æµè§ˆå™¨
    driver = setup_browser()
    
    # åŠ è½½å†å²æ•°æ®
    historical_data = load_historical_data(data_file)
    
    # çˆ¬å–æ–°æ•°æ®
    if "æ ¡æ‹›" in site_name:
        new_jobs, last_page = crawl_campus_data(driver, site_url, START_PAGE, END_PAGE)
    else:
        new_jobs, last_page = crawl_internship_data(driver, site_url, START_PAGE, END_PAGE)
    
    logger.info(f"å…±çˆ¬å–åˆ° {len(new_jobs)} æ¡æ–°èŒä½ä¿¡æ¯")
    
    # å…³é—­æµè§ˆå™¨
    driver.quit()
    
    # æ£€æµ‹æ–°èŒä½
    added_jobs = []
    existing_jobs = historical_data.get("jobs", {})
    
    for job in new_jobs:
        # ä½¿ç”¨å…¬å¸+èŒä½ä½œä¸ºå”¯ä¸€ID
        job_id = f"{job['company']}-{job['position']}"
        
        # å¦‚æœæ˜¯æ–°èŒä½
        if job_id not in existing_jobs:
            added_jobs.append(job)
            existing_jobs[job_id] = job
            logger.info(f"å‘ç°æ–°èŒä½: {job['company']} - {job['position']}")
    
    # æ›´æ–°å†å²æ•°æ®
    historical_data["jobs"] = existing_jobs
    historical_data["last_update"] = datetime.now().isoformat()
    
    # æ¸…ç†è¿‡æœŸèŒä½
    historical_data = clean_expired_jobs(historical_data)
    
    # ä¿å­˜æ›´æ–°åçš„æ•°æ®
    save_historical_data(historical_data, data_file)
    
    # å‡†å¤‡é‚®ä»¶å†…å®¹
    email_body = f"""
    <h2>{site_name}èŒä½æ›´æ–°æŠ¥å‘Š</h2>
    <p>æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    <p>çˆ¬å–é¡µé¢èŒƒå›´: {START_PAGE}-{last_page}</p>
    <p>æ–°å¢èŒä½: {len(added_jobs)} ä¸ª</p>
    <p>æ€»èŒä½æ•°: {len(existing_jobs)} ä¸ª</p>
    """
    
    if added_jobs:
        email_body += "<h3>æ–°å¢èŒä½åˆ—è¡¨:</h3><ul>"
        for job in added_jobs:
            email_body += f"<li>{job['company']} - {job['position']} (æˆªæ­¢: {job['deadline']})</li>"
        email_body += "</ul>"
    
    # ä¿å­˜Excelæ–‡ä»¶å¹¶å‘é€é‚®ä»¶
    if save_excel_file(list(existing_jobs.values()), excel_file, added_jobs=added_jobs):
        # å‘é€å¸¦é™„ä»¶çš„é‚®ä»¶
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–° - {datetime.now().strftime('%Y%m%d')}",
            body=email_body,
            attachment_paths=[excel_file]
        )
    else:
        # å‘é€ä¸å¸¦é™„ä»¶çš„é‚®ä»¶
        email_body += "<p>è­¦å‘Š: æœªèƒ½ç”ŸæˆExcelé™„ä»¶</p>"
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–° - {datetime.now().strftime('%Y%m%d')}",
            body=email_body
        )
    
    logger.info(f"{site_name}ç«™ç‚¹å¤„ç†å®Œæˆ")
    
    # è¿”å›å½“å‰æ‰€æœ‰èŒä½æ•°æ®
    return list(existing_jobs.values())

def main():
    """ä¸»ç¨‹åºï¼ˆæ”¯æŒåŒç«™ç‚¹çˆ¬å–ï¼‰"""
    logger.info(f"å¼€å§‹çˆ¬å–æ‹›è˜ä¿¡æ¯ï¼Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # å¤„ç†æ ¡æ‹›ç«™ç‚¹
        campus_data = process_site(
            "æ ¡æ‹›",
            SITE_URL,
            DATA_FILE_CAMPUS,
            EXCEL_FILE_CAMPUS
        )
        
        # å¤„ç†å®ä¹ ç«™ç‚¹
        intern_data = process_site(
            "å®ä¹ ",
            SITE_URL_INTERNSHIP,
            DATA_FILE_INTERNSHIP,
            EXCEL_FILE_INTERNSHIP
        )
        
        logger.info(f"æ ¡æ‹›èŒä½æ€»æ•°: {len(campus_data)}")
        logger.info(f"å®ä¹ èŒä½æ€»æ•°: {len(intern_data)}")
        logger.info("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºå‘ç”Ÿé”™è¯¯: {e}")
        # å‘é€é”™è¯¯é€šçŸ¥
        send_email(
            subject="æ‹›è˜ä¿¡æ¯çˆ¬å–å‡ºé”™",
            body=f"<h2>çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯</h2><p>{str(e)}</p><p>æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>"
        )


if __name__ == "__main__":
    main()
