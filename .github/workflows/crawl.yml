name: Job Crawler

on:
  schedule:
    - cron: '30 15 * * *'  # 每天UTC时间15:30运行（北京时间23:30）
  workflow_dispatch:       # 允许手动触发

jobs:
  crawl:
    runs-on: ubuntu-latest
    permissions:
      contents: write      # 需要写入权限来更新数据文件

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver libgbm-dev libnss3-dev
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium pandas fake-useragent PyGithub openpyxl python-dateutil
      
      - name: Configure ChromeDriver
        run: |
          # 确保ChromeDriver路径正确
          sudo ln -s /usr/bin/chromedriver /usr/local/bin/chromedriver
          echo "CHROME_PATH=/usr/bin/chromium-browser" >> $GITHUB_ENV
          echo "CHROMEDRIVER_PATH=/usr/local/bin/chromedriver" >> $GITHUB_ENV
          
          # 验证安装
          chromium-browser --version
          chromedriver --version
      
      - name: Run crawler
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PWD: ${{ secrets.EMAIL_PWD }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_NAME: ${{ github.repository }}  # 自动使用当前仓库
        run: python crawler_github.py
      
      - name: Upload Excel artifact
        uses: actions/upload-artifact@v4
        with:
          name: job-data-excel
          path: job_data.xlsx
