import os
import time
import json
import logging
import smtplib
import random
import pandas as pd
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from fake_useragent import UserAgent
import openpyxl
import html

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# é…ç½®å¸¸é‡ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæ€»é¡µæ•°6ï¼Œæ¯æ¬¡çˆ¬2é¡µï¼‰
START_PAGE = 1
END_PAGE = 6  # ç›®æ ‡æ€»é¡µæ•°
MAX_PAGES_PER_SESSION = 2  # æ¯æ¬¡ä¼šè¯æœ€å¤šçˆ¬2é¡µ
SITE_URL = "https://www.givemeoc.com"  # æ ¡æ‹›å²—ä½
SITE_URL_INTERNSHIP = "https://www.givemeoc.com/internship"  # å®ä¹ å²—ä½
WAIT_TIME_MIN = 1
WAIT_TIME_MAX = 3

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
EMAIL_USER = os.environ.get('EMAIL_USER')  # å‘é€é‚®ç®±
EMAIL_PWD = os.environ.get('EMAIL_PWD')  # å‘é€é‚®ç®±å¯†ç 
RECEIVER_EMAILS = os.environ.get('RECEIVER_EMAILS', '').split(';')  # å¤šä¸ªæ¥æ”¶é‚®ç®±ï¼ˆåˆ†å·åˆ†éš”ï¼‰

# ä¸ºä¸¤ç±»å²—ä½åˆ›å»ºç‹¬ç«‹çš„å­˜å‚¨æ–‡ä»¶
DATA_FILE_CAMPUS = "campus_jobs.json"  # æ ¡æ‹›æ•°æ®æ–‡ä»¶
DATA_FILE_INTERNSHIP = "intern_jobs.json"  # å®ä¹ æ•°æ®æ–‡ä»¶
EXCEL_FILE_CAMPUS = "campus_jobs.xlsx"  # æ ¡æ‹›Excel
EXCEL_FILE_INTERNSHIP = "intern_jobs.xlsx"  # å®ä¹ Excel

def setup_browser():
    """é…ç½®æµè§ˆå™¨ï¼ˆæ¯æ¬¡ä¼šè¯é‡æ–°åˆå§‹åŒ–ï¼‰"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument("--incognito")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    
    # æ˜ç¡®æŒ‡å®šChromiumè·¯å¾„ï¼ˆGitHub Actionsä¸“ç”¨ï¼‰
    chrome_options.binary_location = "/usr/bin/chromium-browser"
    
    # éšæœºUser-Agentï¼ˆæ¯æ¬¡ä¼šè¯ä¸åŒï¼‰
    ua = UserAgent()
    chrome_options.add_argument(f"user-agent={ua.random}")
    
    # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
    driver = webdriver.Chrome(options=chrome_options)
    
    # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'
    })
    
    logger.info(f"æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è·¯å¾„: {chrome_options.binary_location}")
    return driver

def crawl_campus_data(driver, site_url, start_page, end_page):
    """çˆ¬å–æ ¡æ‹›æ•°æ®ï¼ˆæ”¯æŒåŠ¨æ€start_pageï¼‰"""
    try:
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # è·³è½¬åˆ°èµ·å§‹é¡µï¼ˆå¦‚æœä¸æ˜¯ç¬¬1é¡µï¼‰
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°æ ¡æ‹›ç¬¬ {start_page} é¡µ...")
                # TODO: æ›¿æ¢ä¸ºå®é™…åˆ†é¡µè¾“å…¥æ¡†é€‰æ‹©å™¨
                page_input = driver.find_element("css selector", "input.crt-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))

                # TODO: æ›¿æ¢ä¸ºå®é™…â€œè·³è½¬â€æŒ‰é’®é€‰æ‹©å™¨
                go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)
                time.sleep(random.gauss(3, 1))
            except Exception as e:
                logger.error(f"æ ¡æ‹›è·³è½¬åˆ°ç¬¬ {start_page} é¡µå¤±è´¥: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # æœ¬æ¬¡ä¼šè¯çˆ¬å–2é¡µï¼ˆstart_pageåˆ°start_page+1ï¼‰
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"æ­£åœ¨çˆ¬å–æ ¡æ‹›ç¬¬ {page} é¡µ...")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£ææ•°æ®ï¼ˆTODO: æ›¿æ¢ä¸ºå®é™…èŒä½åˆ—è¡¨é€‰æ‹©å™¨ï¼‰
            job_items = driver.find_elements("css selector", "table.crt-table tbody tr")

            for item in job_items:
                try:
                    # TODO: æ›¿æ¢ä¸ºå®é™…åˆ—é€‰æ‹©å™¨
                    company = safe_get_text(item, "td.crt-col-company")
                    company_type = safe_get_text(item, "td.crt-col-type")
                    location = safe_get_text(item, "td.crt-col-location")
                    recruitment_type = safe_get_text(item, "td.crt-col-recruitment-type")
                    target = safe_get_text(item, "td.crt-col-target")
                    position = safe_get_text(item, "td.crt-col-position")
                    update_time = safe_get_text(item, "td.crt-col-update-time")
                    deadline = safe_get_text(item, "td.crt-col-deadline")
                    links = safe_get_attr(item, "td.crt-col-links a", "href")
                    notice = safe_get_attr(item, "td.crt-col-notice a", "href")
                    referral = safe_get_text(item, "td.crt-col-referral")
                    notes = safe_get_text(item, "td.crt-col-notes")

                    crawled_data.append({
                        "job_type": "æ ¡æ‹›",
                        "company": company,
                        "company_type": company_type,
                        "location": location,
                        "recruitment_type": recruitment_type,
                        "target": target,
                        "position": position,
                        "update_time": update_time,
                        "deadline": deadline,
                        "links": links,
                        "notice": notice,
                        "referral": referral,
                        "notes": notes,
                        "crawl_time": datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†æ ¡æ‹›æ•°æ®è¡Œå¤±è´¥: {e}")
                    continue

            # ç¿»åˆ°ä¸‹ä¸€é¡µï¼ˆå¦‚æœä¸æ˜¯æœ¬æ¬¡ä¼šè¯æœ€åä¸€é¡µï¼‰
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    # TODO: æ›¿æ¢ä¸ºå®é™…åˆ†é¡µè¾“å…¥æ¡†é€‰æ‹©å™¨
                    page_input = driver.find_element("css selector", "input.crt-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))

                    # TODO: æ›¿æ¢ä¸ºå®é™…â€œè·³è½¬â€æŒ‰é’®é€‰æ‹©å™¨
                    go_button = driver.find_element("css selector", "button.crt-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                except Exception as e:
                    logger.warning(f"æ ¡æ‹›ç¿»é¡µå¤±è´¥ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"æ ¡æ‹›çˆ¬å–å¤±è´¥: {e}")
        return [], start_page

def crawl_internship_data(driver, site_url, start_page, end_page):
    """çˆ¬å–å®ä¹ æ•°æ®ï¼ˆæ”¯æŒåŠ¨æ€start_pageï¼‰"""
    try:
        driver.get(site_url)
        time.sleep(random.uniform(WAIT_TIME_MIN, WAIT_TIME_MAX))
        
        # è·³è½¬åˆ°èµ·å§‹é¡µï¼ˆå¦‚æœä¸æ˜¯ç¬¬1é¡µï¼‰
        if start_page > 1:
            try:
                logger.info(f"è·³è½¬åˆ°å®ä¹ ç¬¬ {start_page} é¡µ...")
                # TODO: æ›¿æ¢ä¸ºå®é™…åˆ†é¡µè¾“å…¥æ¡†é€‰æ‹©å™¨
                page_input = driver.find_element("css selector", "input.int-page-input")
                page_input.clear()
                page_input.send_keys(str(start_page))

                # TODO: æ›¿æ¢ä¸ºå®é™…â€œè·³è½¬â€æŒ‰é’®é€‰æ‹©å™¨
                go_button = driver.find_element("css selector", "button.int-page-go-btn")
                driver.execute_script("arguments[0].click();", go_button)
                time.sleep(random.gauss(3, 1))
            except Exception as e:
                logger.error(f"å®ä¹ è·³è½¬åˆ°ç¬¬ {start_page} é¡µå¤±è´¥: {e}")
                return [], start_page - 1

        crawled_data = []
        current_page = start_page

        # æœ¬æ¬¡ä¼šè¯çˆ¬å–2é¡µï¼ˆstart_pageåˆ°start_page+1ï¼‰
        for page in range(start_page, min(end_page + 1, start_page + MAX_PAGES_PER_SESSION)):
            logger.info(f"æ­£åœ¨çˆ¬å–å®ä¹ ç¬¬ {page} é¡µ...")
            current_page = page

            # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))

            # è§£ææ•°æ®ï¼ˆTODO: æ›¿æ¢ä¸ºå®é™…èŒä½åˆ—è¡¨é€‰æ‹©å™¨ï¼‰
            job_items = driver.find_elements("css selector", "table.int-table tbody tr")

            for item in job_items:
                try:
                    # TODO: æ›¿æ¢ä¸ºå®é™…åˆ—é€‰æ‹©å™¨
                    company = safe_get_text(item, "td.int-col-company")
                    company_type = safe_get_text(item, "td.int-col-type")
                    location = safe_get_text(item, "td.int-col-location")
                    recruitment_type = safe_get_text(item, "td.int-col-recruitment-type")
                    target = safe_get_text(item, "td.int-col-target")
                    position = safe_get_text(item, "td.int-col-position")
                    update_time = safe_get_text(item, "td.int-col-update-time")
                    deadline = safe_get_text(item, "td.int-col-deadline")
                    links = safe_get_attr(item, "td.int-col-links a", "href")
                    notice = safe_get_attr(item, "td.int-col-notice a", "href")
                    referral = safe_get_text(item, "td.int-col-referral")
                    notes = safe_get_text(item, "td.int-col-notes")

                    crawled_data.append({
                        "job_type": "å®ä¹ ",
                        "company": company,
                        "company_type": company_type,
                        "location": location,
                        "recruitment_type": recruitment_type,
                        "target": target,
                        "position": position,
                        "update_time": update_time,
                        "deadline": deadline,
                        "links": links,
                        "notice": notice,
                        "referral": referral,
                        "notes": notes,
                        "crawl_time": datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†å®ä¹ æ•°æ®è¡Œå¤±è´¥: {e}")
                    continue

            # ç¿»åˆ°ä¸‹ä¸€é¡µï¼ˆå¦‚æœä¸æ˜¯æœ¬æ¬¡ä¼šè¯æœ€åä¸€é¡µï¼‰
            if page < min(end_page, start_page + MAX_PAGES_PER_SESSION - 1):
                try:
                    # TODO: æ›¿æ¢ä¸ºå®é™…åˆ†é¡µè¾“å…¥æ¡†é€‰æ‹©å™¨
                    page_input = driver.find_element("css selector", "input.int-page-input")
                    page_input.clear()
                    page_input.send_keys(str(page + 1))

                    # TODO: æ›¿æ¢ä¸ºå®é™…â€œè·³è½¬â€æŒ‰é’®é€‰æ‹©å™¨
                    go_button = driver.find_element("css selector", "button.int-page-go-btn")
                    driver.execute_script("arguments[0].click();", go_button)
                    time.sleep(random.gauss(3, 1))
                except Exception as e:
                    logger.warning(f"å®ä¹ ç¿»é¡µå¤±è´¥ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ: {e}")
                    break

        return crawled_data, current_page
    except Exception as e:
        logger.error(f"å®ä¹ çˆ¬å–å¤±è´¥: {e}")
        return [], start_page

def safe_get_text(element, selector):
    """å®‰å…¨è·å–å…ƒç´ æ–‡æœ¬"""
    try:
        return element.find_element("css selector", selector).text
    except:
        return ""

def safe_get_attr(element, selector, attribute):
    """å®‰å…¨è·å–å…ƒç´ å±æ€§"""
    try:
        return element.find_element("css selector", selector).get_attribute(attribute)
    except:
        return ""

def load_historical_data(data_file):
    """åŠ è½½å†å²æ•°æ®"""
    try:
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            logger.info(f"é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ–°æ•°æ®æ–‡ä»¶: {data_file}")
            return {"last_update": None, "jobs": {}}
    except Exception as e:
        logger.warning(f"åŠ è½½å†å²æ•°æ®å¤±è´¥ï¼Œåˆ›å»ºæ–°æ•°æ®é›†: {e}")
        return {"last_update": None, "jobs": {}}

def save_historical_data(data, data_file):
    """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°"""
    try:
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {data_file}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        return False

def save_excel_file(job_list, filename, added_jobs=None):
    """ä¿å­˜Excelæ–‡ä»¶ï¼ˆå¸¦æ–°å¢é«˜äº®ï¼‰"""
    try:
        CN_HEADERS = {
            "company": "å…¬å¸åç§°",
            "company_type": "å…¬å¸ç±»å‹",
            "location": "å·¥ä½œåœ°ç‚¹",
            "recruitment_type": "æ‹›è˜ç±»å‹",
            "target": "æ‹›è˜å¯¹è±¡",
            "position": "èŒä½åç§°",
            "update_time": "æ›´æ–°æ—¶é—´",
            "deadline": "æˆªæ­¢æ—¶é—´",
            "links": "èŒä½é“¾æ¥",
            "notice": "é€šçŸ¥é“¾æ¥",
            "referral": "å†…æ¨ä¿¡æ¯",
            "notes": "å¤‡æ³¨",
            "crawl_time": "çˆ¬å–æ—¶é—´"
        }
        
        df = pd.DataFrame(job_list).rename(columns=CN_HEADERS)
        
        if added_jobs:
            added_ids = {f"{j['company']}-{j['position']}" for j in added_jobs}
            df['_is_new'] = df.apply(
                lambda x: "æ˜¯" if f"{x['å…¬å¸åç§°']}-{x['èŒä½åç§°']}" in added_ids else "å¦", 
                axis=1
            )
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='æ‹›è˜ä¿¡æ¯')
            worksheet = writer.sheets['æ‹›è˜ä¿¡æ¯']
            
            if added_jobs:
                from openpyxl.styles import PatternFill
                yellow_fill = PatternFill(start_color="FFFF00", fill_type="solid")
                
                for row in worksheet.iter_rows(min_row=2):
                    if row[-1].value == "æ˜¯":
                        for cell in row[:-1]:
                            cell.fill = yellow_fill
                worksheet.delete_cols(worksheet.max_column)
            
            for col in worksheet.columns:
                max_len = max(len(str(cell.value)) for cell in col)
                worksheet.column_dimensions[col[0].column_letter].width = min(max_len + 2, 30)
        
        logger.info(f"Excelå·²ä¿å­˜: {filename}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜Excelå¤±è´¥: {e}")
        return False

def clean_expired_jobs(historical_data):
    """æ¸…ç†è¿‡æœŸèŒä½"""
    logger.info("å¼€å§‹æ¸…ç†è¿‡æœŸèŒä½...")
    current_time = datetime.now()
    expired_count = 0
    for job_id, job in list(historical_data['jobs'].items()):
        if job.get('deadline'):
            try:
                deadline_date = datetime.strptime(job['deadline'], "%Y-%m-%d")
                if deadline_date < current_time:
                    del historical_data['jobs'][job_id]
                    expired_count += 1
            except:
                continue
    logger.info(f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {expired_count} ä¸ªè¿‡æœŸèŒä½")
    return historical_data

def generate_email_html(new_jobs, job_type):
    """ç”Ÿæˆç¾åŒ–çš„HTMLé‚®ä»¶å†…å®¹"""
    styles = """
    <style>
        body { font-family: 'Segoe UI', sans-serif; line-height: 1.6; color: #333; max-width: 800px; margin: 0 auto; padding: 20px; background: #f5f7fa; }
        .header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); color: white; padding: 20px; border-radius: 8px 8px 0 0; text-align: center; margin-bottom: 25px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .header h1 { margin: 0; font-weight: 600; font-size: 24px; }
        .notification-card { background: white; border-radius: 8px; padding: 30px; margin-bottom: 30px; box-shadow: 0 4px 15px rgba(0,0,0,0.08); border: 1px solid #eaeaea; }
        .stats { display: flex; justify-content: space-around; margin-bottom: 25px; text-align: center; }
        .stat-item { background: #f0f5ff; padding: 15px; border-radius: 8px; flex: 1; margin: 0 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
        .stat-item span { display: block; font-size: 28px; font-weight: bold; color: #4b6cb7; margin-bottom: 5px; }
        .job-item { background: #fff; border-left: 4px solid #4b6cb7; margin-bottom: 15px; padding: 15px; border-radius: 0 6px 6px 0; transition: all 0.3s ease; }
        .job-item:hover { transform: translateY(-3px); box-shadow: 0 5px 15px rgba(75, 108, 183, 0.15); }
        .company { font-weight: bold; color: #2c3e50; font-size: 18px; margin-bottom: 5px; }
        .position { font-weight: 600; color: #4b6cb7; font-size: 16px; margin: 10px 0; }
        .meta { display: flex; flex-wrap: wrap; gap: 15px; margin: 10px 0; color: #555; font-size: 14px; }
        .meta span:before { content: "â€¢"; margin-right: 5px; color: #4b6cb7; }
        .deadline { background: #fff9e6; color: #e67e22; padding: 5px 10px; border-radius: 4px; font-weight: 600; display: inline-block; margin-top: 5px; }
        .links a { display: inline-block; background: #4b6cb7; color: white; text-decoration: none; padding: 8px 15px; border-radius: 4px; margin-top: 10px; transition: background 0.3s; }
        .links a:hover { background: #3a559f; }
        .notes { margin-top: 10px; padding: 10px; background: #f8f9fa; border-left: 3px solid #4b6cb7; font-size: 14px; color: #555; }
        .footer { text-align: center; margin-top: 30px; color: #777; font-size: 13px; padding: 15px; border-top: 1px solid #eee; }
    </style>
    """
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>æ–°èŒä½é€šçŸ¥ - {job_type}</title>
        {styles}
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¯ æ–°èŒä½é€šçŸ¥ - {job_type}</h1>
        </div>
        
        <div class="notification-card">
            <div class="stats">
                <div class="stat-item">
                    <span>{len(new_jobs)}</span>
                    æ–°èŒä½
                </div>
                <div class="stat-item">
                    <span>{len(set(job['company'] for job in new_jobs))}</span>
                    å®¶å…¬å¸
                </div>
                <div class="stat-item">
                    <span>{datetime.now().strftime('%m/%d')}</span>
                    æ›´æ–°æ—¥æœŸ
                </div>
            </div>
            
            <div class="job-list">
    """
    
    for job in new_jobs:
        deadline = job.get('deadline', 'æˆªæ­¢æ—¶é—´å¾…å®š')
        links_html = f'<div class="links"><a href="{job["links"]}" target="_blank">æŸ¥çœ‹èŒä½è¯¦æƒ…</a></div>' if job.get('links') else ""
        notes = f'<div class="notes">ğŸ’¡ èŒä½äº®ç‚¹: {html.escape(job.get("notes", ""))}</div>' if job.get('notes') else ""
        
        html_content += f"""
        <div class="job-item">
            <div class="company">{html.escape(job.get('company', ''))}</div>
            <div class="position">ğŸ¢ {html.escape(job.get('position', ''))}</div>
            <div class="meta">
                <span>ğŸ“ {html.escape(job.get('location', ''))}</span>
                <span>ğŸš€ {html.escape(job.get('recruitment_type', ''))}</span>
                <span>ğŸ¯ {html.escape(job.get('target', ''))}</span>
            </div>
            <div class="deadline">â° æˆªæ­¢æ—¶é—´: {html.escape(str(deadline))}</div>
            {notes}
            {links_html}
        </div>
        """
    
    html_content += f"""
            </div>
        </div>
        <div class="footer">
            <p>è‡ªåŠ¨çˆ¬è™«ç³»ç»Ÿç”Ÿæˆ | æŠ“å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>Â© {datetime.now().year} èŒä½ç›‘æ§ç³»ç»Ÿ | å…±å‘ç° {len(new_jobs)} ä¸ªæ–°èŒä½</p>
        </div>
    </body>
    </html>
    """
    return html_content

def send_email(subject, body, attachment_paths=None):
    """å‘é€é‚®ä»¶é€šçŸ¥"""
    try:
        if not EMAIL_USER or not EMAIL_PWD or not RECEIVER_EMAILS:
            logger.warning("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å‘é€")
            return False
            
        smtp_server = "smtp.qq.com"
        smtp_port = 587

        msg = MIMEMultipart()
        msg['From'] = EMAIL_USER
        msg['To'] = ", ".join(RECEIVER_EMAILS)
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'html'))

        if attachment_paths:
            for path in attachment_paths:
                if os.path.exists(path):
                    with open(path, 'rb') as f:
                        part = MIMEApplication(f.read(), Name=os.path.basename(path))
                    part['Content-Disposition'] = f'attachment; filename="{os.path.basename(path)}"'
                    msg.attach(part)

        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PWD)
            server.sendmail(EMAIL_USER, RECEIVER_EMAILS, msg.as_string())
        
        logger.info(f"é‚®ä»¶å·²å‘é€è‡³: {', '.join(RECEIVER_EMAILS)}")
        return True
    except Exception as e:
        logger.error(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")
        return False

def process_site(site_name, site_url, data_file, excel_file):
    """å¤„ç†å•ä¸ªç«™ç‚¹ï¼ˆå¾ªç¯çˆ¬å–1-6é¡µï¼Œæ¯æ¬¡2é¡µï¼‰"""
    logger.info(f"å¼€å§‹å¤„ç† {site_name} ç«™ç‚¹ï¼ˆ1-{END_PAGE}é¡µï¼Œæ¯æ¬¡2é¡µï¼‰")
    
    # åŠ è½½å†å²æ•°æ®ï¼ˆé¦–æ¬¡ä¸ºç©ºï¼‰
    historical_data = load_historical_data(data_file)
    existing_jobs = historical_data.get("jobs", {})
    all_new_jobs = []  # ç´¯ç§¯æ‰€æœ‰ä¼šè¯çš„æ–°èŒä½
    
    # å¾ªç¯çˆ¬å–ï¼šæ¯æ¬¡2é¡µï¼Œç›´åˆ°è¦†ç›–1-6é¡µ
    current_start_page = START_PAGE
    while current_start_page <= END_PAGE:
        # æ¯æ¬¡ä¼šè¯é‡æ–°åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆå…³é”®ï¼šé¿å…è¿ç»­ä¼šè¯è¢«æ”¶è´¹ï¼‰
        driver = setup_browser()
        
        # æœ¬æ¬¡ä¼šè¯çˆ¬å–çš„é¡µæ•°èŒƒå›´ï¼ˆå¦‚1-2ã€3-4ã€5-6ï¼‰
        current_end_page = min(current_start_page + MAX_PAGES_PER_SESSION - 1, END_PAGE)
        logger.info(f"=== å¼€å§‹ç¬¬ {current_start_page}-{current_end_page} é¡µçˆ¬å– ===")
        
        # è°ƒç”¨å¯¹åº”çˆ¬å–å‡½æ•°ï¼ˆæ ¡æ‹›/å®ä¹ ï¼‰
        if "æ ¡æ‹›" in site_name:
            new_jobs, last_page = crawl_campus_data(driver, site_url, current_start_page, current_end_page)
        else:
            new_jobs, last_page = crawl_internship_data(driver, site_url, current_start_page, current_end_page)
        
        # å…³é—­å½“å‰æµè§ˆå™¨ï¼ˆå®Œæˆæœ¬æ¬¡ä¼šè¯ï¼‰
        driver.quit()
        
        # å¤„ç†æœ¬æ¬¡ä¼šè¯çš„æ–°èŒä½
        for job in new_jobs:
            job_id = f"{job['company']}-{job['position']}"
            if job_id not in existing_jobs:
                all_new_jobs.append(job)
                existing_jobs[job_id] = job
                logger.info(f"å‘ç°æ–°èŒä½: {job['company']} - {job['position']}")
        
        # æ›´æ–°ä¸‹ä¸€æ¬¡çˆ¬å–çš„èµ·å§‹é¡µ
        current_start_page = last_page + 1
        logger.info(f"=== å®Œæˆç¬¬ {current_start_page - MAX_PAGES_PER_SESSION}-{last_page} é¡µçˆ¬å– ===")
        
        # çˆ¬å–é—´éš”ï¼ˆæ¨¡æ‹Ÿäººç±»æ“ä½œé—´éš”ï¼‰
        if current_start_page <= END_PAGE:
            sleep_time = random.uniform(5, 10)  # 5-10ç§’é—´éš”
            logger.info(f"ç­‰å¾… {sleep_time:.1f} ç§’åå¼€å§‹ä¸‹ä¸€æ¬¡çˆ¬å–...")
            time.sleep(sleep_time)
    
    # å…¨éƒ¨çˆ¬å–å®Œæˆåï¼Œæ›´æ–°å†å²æ•°æ®
    historical_data["jobs"] = existing_jobs
    historical_data["last_update"] = datetime.now().isoformat()
    historical_data = clean_expired_jobs(historical_data)  # æ¸…ç†è¿‡æœŸèŒä½
    save_historical_data(historical_data, data_file)
    
    # ç”ŸæˆExcelå’Œå‘é€é‚®ä»¶ï¼ˆæ±‡æ€»æ‰€æœ‰æ–°èŒä½ï¼‰
    logger.info(f"{site_name} å…¨éƒ¨çˆ¬å–å®Œæˆï¼Œå…±å‘ç° {len(all_new_jobs)} ä¸ªæ–°èŒä½")
    if save_excel_file(list(existing_jobs.values()), excel_file, added_jobs=all_new_jobs):
        # ä½¿ç”¨ç¾åŒ–çš„HTMLé‚®ä»¶
        email_body = generate_email_html(all_new_jobs, site_name) if all_new_jobs else f"""
        <div class="header"><h1>ğŸ¯ {site_name}èŒä½æ›´æ–°</h1></div>
        <div class="notification-card">
            <p>æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>å·²çˆ¬å–1-{END_PAGE}é¡µï¼Œæœ¬æ¬¡æ— æ–°å¢èŒä½</p>
            <p>æ€»èŒä½æ•°: {len(existing_jobs)} ä¸ª</p>
        </div>
        """
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–°ï¼ˆ1-{END_PAGE}é¡µï¼‰- {datetime.now().strftime('%Y%m%d')}",
            body=email_body,
            attachment_paths=[excel_file]
        )
    else:
        send_email(
            subject=f"{site_name}æ‹›è˜ä¿¡æ¯æ›´æ–°ï¼ˆ1-{END_PAGE}é¡µï¼‰- {datetime.now().strftime('%Y%m%d')}",
            body=f"<h3>{site_name}çˆ¬å–å®Œæˆ</h3><p>æ–°èŒä½: {len(all_new_jobs)} ä¸ª</p><p>Excelç”Ÿæˆå¤±è´¥</p>"
        )
    
    return list(existing_jobs.values())

def main():
    """ä¸»ç¨‹åº"""
    logger.info(f"å¼€å§‹çˆ¬å–æ‹›è˜ä¿¡æ¯ï¼ˆ1-{END_PAGE}é¡µï¼Œæ¯æ¬¡2é¡µï¼‰ï¼Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # å¤„ç†æ ¡æ‹›ç«™ç‚¹
        campus_data = process_site(
            "æ ¡æ‹›",
            SITE_URL,
            DATA_FILE_CAMPUS,
            EXCEL_FILE_CAMPUS
        )
        
        # å¤„ç†å®ä¹ ç«™ç‚¹
        intern_data = process_site(
            "å®ä¹ ",
            SITE_URL_INTERNSHIP,
            DATA_FILE_INTERNSHIP,
            EXCEL_FILE_INTERNSHIP
        )
        
        logger.info(f"æ ¡æ‹›èŒä½æ€»æ•°: {len(campus_data)}")
        logger.info(f"å®ä¹ èŒä½æ€»æ•°: {len(intern_data)}")
        logger.info("æ‰€æœ‰ä»»åŠ¡å®Œæˆ")
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºé”™è¯¯: {e}")
        send_email(
            subject="æ‹›è˜çˆ¬å–å‡ºé”™é€šçŸ¥",
            body=f"<h2>çˆ¬å–å¤±è´¥</h2><p>é”™è¯¯: {str(e)}</p><p>æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>"
        )


if __name__ == "__main__":
    main()
